\documentclass[a4paper]{article} 
\usepackage{polski}
\usepackage[utf8]{inputenc} 
\usepackage[OT4]{fontenc} 
\usepackage{graphicx,color}
\usepackage{url} 
\usepackage{hyperref}
\usepackage[a4paper,left=3cm,right=3cm,top=3cm,bottom=3cm,headsep=1.2cm]{geometry}
\usepackage{float} 

\title{\textbf{Sekwencjonowanie łańcuchów DNA}}
\date{}
\author{Paweł Lampe \and Jakub Szwachła}

\begin{document}

\maketitle

\section{Wstęp}

\section{Opis algorytmów}

\subsection{Problem 3: Sekwencjonowanie łańcuchów DNA z błędami negatywnymi i pozytywnymi}      %% fix a bit

Dla przypadku ogólnego przygotowaliśmy prosty algorytm zachłanny. Problem zamodelowaliśmy w postaci grafu Łysowa,
w którym każdy wierzchołek odpowiada jednemu słowu ze spektrum. Wagi krawędzi odpowiadają przesunięciu etykiet
względem siebie.

Algorytm rozpoczyna się w zadanym wierzchołku. W każdym kroku wybieramy najbliższy nieodwiedzony wierzchołek w stosunku
do poprzednio odwiedzonego. Rzecz jasna algorytm działa dopóki wyprodukowana sekwencja nie przekroczy długością docelowej
lub dopóki nie odwiedzimy wszystkich wierzchołków.

Z racji na zadziwiająco dobre wyniki postanowiliśmy z algorytmu wycisnąć jeszcze więcej. W toku optymalizacji powyższe
przeszukiwanie jednokierunkowe wzbogaciliśmy o dodatkowy kierunek. Postanowiliśmy rozważyć nie tylko następniki ostatnio
odwiedzonego wierzchołka (ogona łańcucha), lecz także poprzedniki głowy łańcucha. Tak oto obecnie
algorytm jest niejako rozszerzającym się łańcuchem, przy czym rozszerzanie następuje od głowy oraz od ogona
wybierając najkrótszą krawędź niezależnie od strony. Co więcej algorytm uruchamiany jest oddzielnie dla każdego
wierzchołka w roli startowego, po czym wybierany jest najlepszy ze zbioru wyników.

Złożoność czasowa samego algorytmu jest oczywista i wynosi $O(N^2)$, gdzie N to ilość wierzchołków w grafie. Algorytm jest
jednak uruchamiany N-krotnie z różnymi wierzchołkami startowymi, co pogarsza ową złożoność do $O(N^3)$.

%% skomentować poprawę wyników

\subsection{Problem 2: Sekwencjonowanie łańcuchów DNA z błędami pozytywnymi}
Instancje z błędami wyłącznie pozytywnymi, to zdecydowanie najprostsze przypadki z punktu widzenia złożoności problemu.
W przypadku występowania takich błędów, w grafie Pevznera musi istnieć przynajmniej jedna ścieżka przechodząca przez
przynajmniej $n-l+1$ krawędzi, gdzie $n$ to długość sekwencji oryginalnej a $l$ to długość słowa. W praktyce oznacza to tyle,
że algorytm powinien zwrócić przynajmniej jedno rozwiązanie długości $n$ przy użyciu $n-l+1$ słów.

Zaproponowana przez nas heurystyka działa trój-etapowo:
\begin{itemize}
\item Na początku szuka wszystkich spójnych składowych i zapamiętuje zbiory wierzchołków do nich przynależnych
\item Dalej, iterując po spójnych składowych, szuka na tyle dużych, aby możliwe było w ogóle pomieszczenie tam ścieżki
o długości $n-l+1$ krawędzi. Jeżeli taka spójna składowa zostanie odnaleziona, wewnątrz niej rozpoczyna się seria
wyszukiwań DFS
\item Jako wierzchołki startowe dla DFS wybierane są tylko te które mają zerowy stopień wejściowy oraz niezerowy
stopień wyjściowy. W przypadku gdy takich nie ma, wybierane są kolejno wszystkie wierzchołki.

W przypadku znalezienia rozwiązania, jest ono niezwłocznie zwracane, przez co przerwaniu ulegają wszystkie iteracje.
Nie ratuje to jednak w żaden sposób złożoności, którą jest $O(V*E^2)$, gdzie $V$ to ilość wierzchołków a $E$ to ilość
krawędzi w grafie Pevznera. W optymistycznym przypadku jednak algorytm działa błyskawicznie, z racji, iż graf jest
bardzo rzadki.

\subsection{Problem 1: Sekwencjonowanie łańcuchów DNA z błędami negatywnymi}
Przypadki z błędami wyłącznie negatywnymi można wewnętrznie podzielić na dwie podgrupy:
\begin{itemize}
\item braki w spektrum
\item błędy wynikające z powtórzeń
\end{itemize}
Z racji powyższego podziału, zaproponowana przez nas heurystyka wykonuje przed przystąpieniem do działania preprocesing.

Zlicza ona mianowicie ilość spójnych składowych w grafie. Jeśli jest dokładnie jedna to pewnym jest fakt, że w grafie
mamy do czynienia tylko i wyłącznie z błędami negatywnymi wynikającymi z powtórzeń. W przeciwnym razie, w grafie
mogą występować dowolne błędy z podgrup wymienionych powyżej.

Preprocesing wykonujemy więc celem zadecydowania jaką podjąć strategię.

Jeśli mamy do czynienia z jedną spójną składową w grafie, czyli na pewno z błędami wynikającymi z powtórzeń, sytuacja jest
stosunkowo prosta. Wystarczy zadbać aby zaszedł warunek konieczny istnienia ścieżki Eulera dla grafu skierowanego. 
Oznacza to, że trzeba znaleźć te wierzchołki których stopień wejściowy jest różny od stopnia wyjściowego, gdzie żadna
z tych liczb nie jest zerem. Gdy zostaną odnalezione, należy je odpowiednio ze sobą połączyć. Dokonać tego można poprzez
wybranie dowolnego z tych wierzchołków, oraz wyszukanie komplementarnego metodą BFS.

Alternatywną sytuacją jest przypadek, gdy w grafie jest więcej niż jedna spójna składowa. %% opisać IF!=1

Jeżeli w powyższych metodach wszystko przebiegnie bezproblemowo, wystarczy poszukać wierzchołka początkowego dla ścieżki
Eulera (stopień wejściowy = 0 oraz stopień wyjściowy = 1) oraz odszukać tą ścieżkę celem podania rozwiązania.

Algorytm ten jest jak widać zorientowany na dwa przypadki. %% napisać o FAILach

\section{Wyniki}


\begin{table}[H]
\caption{Porównaniu algorytmów dla problemów 3 i 1}
\begin{tabular}{|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\multicolumn{1}{|l|}{P3} & \multicolumn{1}{l|}{P1} &
\multicolumn{1}{l|}{optimum} & \multicolumn{1}{l|}{P3 odl. od opt.} &
\multicolumn{1}{l|}{P1 odl. od opt.} \\ \hline
\multicolumn{5}{|c|}{Błędy negatywne losowe} \\ \hline
160 & 160 & 160 & \textbf{0} & \textbf{0} \\ \hline
120 & 120 & 120 & \textbf{0} & \textbf{0} \\ \hline
160 & 139 & 160 & \textbf{0} & 21 \\ \hline
117 & 120 & 120 & 3 & \textbf{0} \\ \hline
160 & 160 & 160 & \textbf{0} & \textbf{0} \\ \hline
117 & 120 & 120 & 3 & \textbf{0} \\ \hline
240 & 240 & 240 & \textbf{0} & \textbf{0} \\ \hline
178 & 180 & 180 & 2 & \textbf{0} \\ \hline
235 & 240 & 240 & 5 & \textbf{0} \\ \hline
178 & 180 & 180 & 2 & \textbf{0} \\ \hline
240 & 240 & 240 & \textbf{0} & \textbf{0} \\ \hline
176 & 111 & 180 & 4 & 69 \\ \hline
316 & 271 & 320 & 4 & 49 \\ \hline
230 & 73 & 240 & 10 & 167 \\ \hline
318 & 320 & 320 & 2 & \textbf{0} \\ \hline
229 & 240 & 240 & 11 & \textbf{0} \\ \hline
312 & 117 & 320 & 8 & 203 \\ \hline
229 & 18 & 240 & 11 & 222 \\ \hline
392 & 399 & 400 & 8 & 1 \\ \hline
296 & 293 & 300 & 4 & 7 \\ \hline
400 & 400 & 400 & \textbf{0} & \textbf{0} \\ \hline
296 & 60 & 300 & 4 & 240 \\ \hline
391 & 397 & 400 & 9 & 3 \\ \hline
300 & 297 & 300 & \textbf{0} & 3 \\ \hline
\multicolumn{5}{|c|}{Błędy negatywne wynikające z powtórzeń} \\ \hline
493 & 498 & 498 & 5 & \textbf{0} \\ \hline
488 & 492 & 492 & 4 & \textbf{0} \\ \hline
488 & 488 & 488 & \textbf{0} & \textbf{0} \\ \hline
475 & 482 & 482 & 7 & \textbf{0} \\ \hline
468 & 0 & 468 & \textbf{0} & 468 \\ \hline
\end{tabular}
\label{}
\end{table}

\begin{table}[H]
\caption{Porównaniu algorytmów dla problemów 3 i 2}
\begin{tabular}{|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\multicolumn{1}{|l|}{P3} & \multicolumn{1}{l|}{P2} &
\multicolumn{1}{l|}{optimum} & \multicolumn{1}{l|}{P3 odl. od opt.} &
\multicolumn{1}{l|}{P2 odl. od opt.} \\ \hline
\multicolumn{5}{|c|}{Błędy pozytywne losowe} \\ \hline
200 & 200 & 200 & \textbf{0} & \textbf{0} \\ \hline
200 & 200 & 200 & \textbf{0} & \textbf{0} \\ \hline
200 & 200 & 200 & \textbf{0} & \textbf{0} \\ \hline
300 & 300 & 300 & \textbf{0} & \textbf{0} \\ \hline
300 & 300 & 300 & \textbf{0} & \textbf{0} \\ \hline
300 & 300 & 300 & \textbf{0} & \textbf{0} \\ \hline
400 & 400 & 400 & \textbf{0} & \textbf{0} \\ \hline
400 & 400 & 400 & \textbf{0} & \textbf{0} \\ \hline
386 & 400 & 400 & 14 & \textbf{0} \\ \hline
500 & 500 & 500 & \textbf{0} & \textbf{0} \\ \hline
496 & 500 & 500 & 4 & \textbf{0} \\ \hline
500 & 500 & 500 & \textbf{0} & \textbf{0} \\ \hline
\multicolumn{5}{|c|}{Błędy pozytywne, przekłamania na
końcach oligonukleotydów} \\ \hline
171 & 200 & 200 & 29 & \textbf{0} \\ \hline
179 & 200 & 200 & 21 & \textbf{0} \\ \hline
178 & 200 & 200 & 22 & \textbf{0} \\ \hline
270 & 300 & 300 & 30 & \textbf{0} \\ \hline
267 & 300 & 300 & 33 & \textbf{0} \\ \hline
269 & 300 & 300 & 31 & \textbf{0} \\ \hline
353 & 400 & 400 & 47 & \textbf{0} \\ \hline
334 & 400 & 400 & 66 & \textbf{0} \\ \hline
361 & 400 & 400 & 39 & \textbf{0} \\ \hline
435 & 500 & 500 & 65 & \textbf{0} \\ \hline
434 & 500 & 500 & 66 & \textbf{0} \\ \hline
429 & 500 & 500 & 71 & \textbf{0} \\ \hline
\end{tabular}
\label{}
\end{table}

\section{Wnioski}


\end{document}
